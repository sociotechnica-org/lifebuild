# Strategy - AI as Teammates

## WHAT: The Strategy

Agents with defined jobs, permissions, and coordination capabilities provide leverage previously available only to people with human staff. This is Strategic Plank 3 — the third of three independent bets LifeBuild is built on.

## WHERE: Ecosystem

- Type: Strategic Bet
- Serves: [[Need - Relatedness]] — agents function as colleagues, not tools
- Serves: [[Need - Competence]] (secondary) — agents enable accomplishment
- Implementing principles: [[Principle - Earn Don't Interrogate]], [[Principle - Guide When Helpful]]
- Core team: [[Agent - Jarvis]], [[Agent - Mesa]], [[Agent - Marvin]], [[Agent - Cameron]], [[Agent - Devin]], [[Agent - Conan]]
- Category advisors: [[System - Category Advisors]], [[Agent - Maya]], [[Agent - Atlas]], [[Agent - Brooks]], [[Agent - Grace]], [[Agent - Reed]], [[Agent - Finn]], [[Agent - Indie]], [[Agent - Sage]]
- Systems: [[Standard - Service Levels]], [[Standard - Knowledge Framework]], [[System - Processing Layer]]
- Systems: [[System - Progressive Knowledge Capture]], [[System - Smoke Signals]]
- Artifacts: [[Artifact - The Charter]], [[Artifact - The Agenda]]

## WHY: Belief

People are drowning in work they shouldn't be doing themselves. Research, scheduling, coordination, follow-up, routine decisions — these consume hours that could go toward higher-value thinking or actual living. The constraint isn't knowledge or willpower; it's bandwidth.

AI has made delegation radically more accessible. But most people still treat AI as a tool they "use" — a search engine with better answers, a writing assistant they prompt. This captures maybe 10% of the potential.

The real unlock is AI as _teammates_ — agents with defined roles, ongoing responsibilities, and the judgment to act within appropriate bounds. The difference between "tool I use" and "teammate I work with" is the difference between doing everything yourself with occasional assistance versus having a staff that handles work on your behalf.

The bet: if directors have AI agents with defined jobs, appropriate permissions, and the ability to coordinate — teammates rather than tools — they can operate at a level of effectiveness previously available only to people with human staff, while maintaining sovereignty over the decisions that matter.

## WHEN: Timeline
- Status: stable
- Since: v1.0

## HOW: Application

### Maturity Ladder

| Level | Name                   | What It Is                                          |
| ----- | ---------------------- | --------------------------------------------------- |
| 0     | Status Quo             | No AI or generic chat                               |
| 1     | Specialized Agents     | Each room has domain-specific agent (current state) |
| 2     | Extended to Real World | Agents handle email, calendar, web research         |
| 3     | Jobs and Permissions   | Agents have standing authority, act proactively     |
| 4     | Agent Coordination     | Agents hand off to each other                       |
| 5     | Tiered Authority       | Seniority structure, escalation paths               |
| 6     | Learning and Memory    | Agents remember, learn patterns, improve over time  |
| 7+    | Autonomous Team        | Agents with genuine judgment, minimal oversight     |

**Current state:** Level 1. Specialized agents in rooms, reactive help. No proactive behavior or agent-to-agent coordination yet.

### What Following This Looks Like

- Each agent has a defined job and domain: Jarvis orchestrates, Mesa navigates, Cameron prioritizes. The director delegates to the right agent by role, not by prompting a generic interface.
- Agents earn trust progressively through demonstrated competence at lower levels before receiving broader authority. A new agent starts reactive and graduates to proactive only after proving reliability.
- The director maintains sovereignty over high-stakes decisions (choosing Gold projects, reclassifying streams) while agents handle research, coordination, and routine follow-up autonomously within their defined permissions.

### What Violating This Looks Like

- **Treating agents as generic chat interfaces** — Level 0 is "no AI or generic chat." An agent without a defined job, domain, and permissions is just a chatbot. The teammate model requires specialization: Jarvis orchestrates, Mesa navigates, Cameron prioritizes. Generic "ask me anything" violates the entire ladder.
- **Skipping to autonomous behavior without earning trust** — Jumping from Level 1 (specialized, reactive) to Level 5+ (tiered authority) without progressing through jobs-and-permissions and coordination. Trust is earned progressively, not declared.
- **Agents replacing director judgment instead of empowering it** — Agents that make decisions the director should make — choosing Gold projects, reclassifying streams, archiving work — violate sovereignty. The strategy is teammates, not replacement managers.

### Decision Heuristic

When choosing between the director doing work personally and delegating to an agent, delegate — but only within the agent's defined role and earned authority level, never beyond it.

## Tensions

- With director sovereignty — agents must empower, not replace, director judgment
- With privacy — knowledge acquisition must respect boundaries ([[Principle - Earn Don't Interrogate]])
- Independent from other planks — can succeed or fail independently of Visual and Process bets
